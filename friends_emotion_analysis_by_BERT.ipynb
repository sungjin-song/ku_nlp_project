{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "friends_emotion_analysis_by_BERT",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b433a81355e4463b743ee99ef966170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0eeca8dcb2a4f5bad6342940520fc42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4bb1a15729d94f00876f56d9f1ee739d",
              "IPY_MODEL_bd6a91b6e76a4df790f76efdbc1c06fe"
            ]
          }
        },
        "e0eeca8dcb2a4f5bad6342940520fc42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bb1a15729d94f00876f56d9f1ee739d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8cdee3ce9ad449659ec862fe67925eb9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d545b7b7889d4ea7942fbc484c600499"
          }
        },
        "bd6a91b6e76a4df790f76efdbc1c06fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a03dd738507548dbaa955143b4d14a2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 812kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d8e27b44fef4d0492dfc01be67e5e9a"
          }
        },
        "8cdee3ce9ad449659ec862fe67925eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d545b7b7889d4ea7942fbc484c600499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a03dd738507548dbaa955143b4d14a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d8e27b44fef4d0492dfc01be67e5e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e138aef8f4414ffc96aae7f50b011632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_809cfb811b3b47518949366c311d2107",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c2ba057c361e4043b685f2372bd2a652",
              "IPY_MODEL_3463d122158a43a6a0cf656f0d9b8059"
            ]
          }
        },
        "809cfb811b3b47518949366c311d2107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2ba057c361e4043b685f2372bd2a652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0930618e137e4266a4c1ff232823bfea",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4e7751da7004b538cc7afccfe191110"
          }
        },
        "3463d122158a43a6a0cf656f0d9b8059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_445ddac83d6e42498479b0bea3257b70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 7.65kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fbaae8ab5f54d679afdb05fafaeccdf"
          }
        },
        "0930618e137e4266a4c1ff232823bfea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4e7751da7004b538cc7afccfe191110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "445ddac83d6e42498479b0bea3257b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fbaae8ab5f54d679afdb05fafaeccdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV9QvJVzxRAm",
        "outputId": "d02e4217-cbac-4cb9-df80-a4b644bb7812"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BwOxgtBxpTC"
      },
      "source": [
        "DATA_PATH = 'gdrive/My Drive/Colab Notebooks/KU-NLP-2020-1/Data/'\n",
        "import sys\n",
        "sys.path.append(DATA_PATH)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZewOX-D9BLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf204d68-59da-467f-990c-04a222ffbcde"
      },
      "source": [
        "#!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl\n",
        "!pip install transformers --quiet # package installer for python"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.5MB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 28.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 56.2MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6idZebToz_Wa"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm_notebook\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm\n",
        "from transformers import AdamW, BertConfig\n",
        "from transformers import BertModel, BertForSequenceClassification, BertTokenizer\n",
        "from transformers import ElectraTokenizer\n",
        "from transformers import ElectraModel, ElectraForSequenceClassification\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from model import BertForMultiLabelClassification\n",
        "from multilabel_pipeline import MultiLabelPipeline\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_9zhym7K9EG",
        "outputId": "5a84ce6f-370f-48aa-8f6e-50651c360407"
      },
      "source": [
        "# GPU 및 TPU 사용여부 설정\n",
        "tpu_use = False\n",
        "# Acquires the default Cloud TPU core and moves the model to it\n",
        "if tpu_use == True:\n",
        "    device = xm.xla_device()\n",
        "    print(device)      \n",
        "elif torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'    \n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')   "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "7b433a81355e4463b743ee99ef966170",
            "e0eeca8dcb2a4f5bad6342940520fc42",
            "4bb1a15729d94f00876f56d9f1ee739d",
            "bd6a91b6e76a4df790f76efdbc1c06fe",
            "8cdee3ce9ad449659ec862fe67925eb9",
            "d545b7b7889d4ea7942fbc484c600499",
            "a03dd738507548dbaa955143b4d14a2c",
            "2d8e27b44fef4d0492dfc01be67e5e9a"
          ]
        },
        "id": "VKYIuzDw6mCq",
        "outputId": "2ab6e2e4-059f-4850-adfc-2a9ef20d7af1"
      },
      "source": [
        "# Bert 모델 설정\n",
        "pretrained_weights = 'bert-base-uncased' #google/electra-small-generator' 'monologg/bert-base-cased-goemotions-ekman' 'bert-large-cased' \n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
        "#tokenizer = ElectraTokenizer.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b433a81355e4463b743ee99ef966170",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xzpFG2Azpx6"
      },
      "source": [
        "# 데이터셋 로드\n",
        "import json\n",
        "\n",
        "data = {'train': {'speaker': [], 'utterance': [], 'emotion': []},\n",
        "        'dev': {'speaker': [], 'utterance': [], 'emotion': []},\n",
        "        'test': {'speaker': [], 'utterance': [], 'emotion': []}}\n",
        "\n",
        "for dtype in ['train', 'dev', 'test']:\n",
        "  for dialog in json.loads(open(DATA_PATH + 'friends_' + dtype + '.json').read()):\n",
        "    for line in dialog:\n",
        "      data[dtype]['speaker'].append(line['speaker'])\n",
        "      data[dtype]['utterance'].append(line['utterance'])\n",
        "      data[dtype]['emotion'].append(line['emotion'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brBAWhKybo-3",
        "outputId": "48b90b4c-4c54-4e18-afa6-8de71864a5cd"
      },
      "source": [
        "# 캐글 테스트셋 로드\r\n",
        "test_data = pd.read_csv(DATA_PATH + \"en_data.csv\", sep=',')\r\n",
        "print(test_data.shape)\r\n",
        "print(test_data[:2])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1623, 5)\n",
            "   id  i_dialog  i_utterance speaker                      utterance\n",
            "0   0         0            0  Phoebe  Alright, whadyou do with him?\n",
            "1   1         0            1  Monica              Oh! You're awake!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVhiZ12D6xXU",
        "outputId": "30de196d-a0cc-4543-9e42-d659a769f9b5"
      },
      "source": [
        "e2i_dict = dict((emo, i) for i, emo in enumerate(set(data['train']['emotion'])))\n",
        "i2e_dict = {i: e for e, i in e2i_dict.items()}\n",
        "e2i_dict"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'anger': 7,\n",
              " 'disgust': 0,\n",
              " 'fear': 3,\n",
              " 'joy': 1,\n",
              " 'neutral': 6,\n",
              " 'non-neutral': 4,\n",
              " 'sadness': 2,\n",
              " 'surprise': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XVPwHF_YSRC",
        "outputId": "8238dc2a-a625-4898-be94-5df7d4a187c2"
      },
      "source": [
        "# 추가 학습 데이터 가공\r\n",
        "train_add_data = pd.read_csv(DATA_PATH + \"kaggle_train.txt\", sep=';', names=['utterance','emotion'])\r\n",
        "# 불필요 항목 제거\r\n",
        "train_add_data = train_add_data.drop(train_add_data[train_add_data.emotion == 'love'].index) \r\n",
        "train_add_data['speaker'] = 'Anonymous'\r\n",
        "train_add_data.head"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                utterance  emotion    speaker\n",
              "0                                i didnt feel humiliated  sadness  Anonymous\n",
              "1      i can go from feeling so hopeless to so damned...  sadness  Anonymous\n",
              "2       im grabbing a minute to post i feel greedy wrong    anger  Anonymous\n",
              "4                                   i am feeling grouchy    anger  Anonymous\n",
              "5      ive been feeling a little burdened lately wasn...  sadness  Anonymous\n",
              "...                                                  ...      ...        ...\n",
              "19995  i just keep feeling like someone is being unki...    anger  Anonymous\n",
              "19996  im feeling a little cranky negative after this...    anger  Anonymous\n",
              "19997  i feel that i am useful to my people and that ...      joy  Anonymous\n",
              "19998  im feeling more comfortable with derby i feel ...      joy  Anonymous\n",
              "19999  i feel all weird when i have to meet w people ...     fear  Anonymous\n",
              "\n",
              "[18359 rows x 3 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lBrGnljgNpf"
      },
      "source": [
        "# 추가 학습 데이터 기존 훈련데이터 추가\r\n",
        "for idx, add_data in train_add_data.iterrows():\r\n",
        "  data['train']['utterance'].append(add_data[0])\r\n",
        "  data['train']['emotion'].append(add_data[1])\r\n",
        "  data['train']['speaker'].append(add_data[2])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "e1M949Rra6C4",
        "outputId": "0543a863-c0b1-491c-b7ff-c1b2fda3751c"
      },
      "source": [
        "e2i_cnt = [e2i_dict[data['train']['emotion'][i]] for i in range(len(data['train']['utterance']))]\r\n",
        "\r\n",
        "#감정별 데이터 분포 확인\r\n",
        "e2i_pd = pd.DataFrame(e2i_cnt, columns=['emotion'])\r\n",
        "e2i_pd[\"emotion_nm\"] = e2i_pd.apply(lambda x : i2e_dict[x[\"emotion\"]] , axis = 1 )\r\n",
        "e2i_pd.groupby(e2i_pd['emotion']).count()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion_nm</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         emotion_nm\n",
              "emotion            \n",
              "0               240\n",
              "1              8044\n",
              "2              6148\n",
              "3              2558\n",
              "4              2017\n",
              "5              1939\n",
              "6              4752\n",
              "7              3222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e138aef8f4414ffc96aae7f50b011632",
            "809cfb811b3b47518949366c311d2107",
            "c2ba057c361e4043b685f2372bd2a652",
            "3463d122158a43a6a0cf656f0d9b8059",
            "0930618e137e4266a4c1ff232823bfea",
            "e4e7751da7004b538cc7afccfe191110",
            "445ddac83d6e42498479b0bea3257b70",
            "7fbaae8ab5f54d679afdb05fafaeccdf"
          ]
        },
        "id": "v4SvEZyJZN02",
        "outputId": "cca79db3-07f3-4cbd-a1af-409392a52dc1"
      },
      "source": [
        "# BERT 모델 config 설정\n",
        "config = BertConfig.from_pretrained(\n",
        "        pretrained_weights,\n",
        "        num_labels=len(e2i_dict),\n",
        "        id2label=i2e_dict,\n",
        "        label2id=e2i_dict\n",
        "    )\n",
        "\n",
        "#print(config.num_labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e138aef8f4414ffc96aae7f50b011632",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPxgi5ueZ8Hf",
        "outputId": "4bbd1aa4-07a8-4b59-de00-f06797e0018b"
      },
      "source": [
        "# 데이터셋 샘플 출력\n",
        "print(\"대화\", data['train']['utterance'][:5 ]) \n",
        "print(\"화자\",data['train']['speaker'][:5] )\n",
        "print(\"감정\",data['train']['emotion'][:5] )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "대화 ['also I was the point person on my company\\x92s transition from the KL-5 to GR-6 system.', 'You must\\x92ve had your hands full.', 'That I did. That I did.', 'So let\\x92s talk a little bit about your duties.', 'My duties?  All right.']\n",
            "화자 ['Chandler', 'The Interviewer', 'Chandler', 'The Interviewer', 'Chandler']\n",
            "감정 ['neutral', 'neutral', 'neutral', 'neutral', 'surprise']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47esym17Hwi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f10438-25e9-481c-dba7-5a90f6106f74"
      },
      "source": [
        "# 배치 사이즈 조정\n",
        "batch_size = 2\n",
        "# 우리 모델은 한 문장을 사용합니다. (컨텍스트도 파악하십시오.)\n",
        "# 우리 모델은 화자 정보를 고려하지 않습니다. (정보를 고려하십시오.)\n",
        "\n",
        "# 테스트데이터 pytorch dataset클래스 활용 전처리\n",
        "def Embedding(texts, speakers, labels, batch_size, final_flag=False):\n",
        "    # BERT의 입력 형식에 맞게 변환\n",
        "\n",
        "    bf_text = ''\n",
        "    sentences = []\n",
        "    for text, speaker in zip(texts, speakers):       \n",
        "      #sentences.append(\"[CLS] \" + str(text) + \" [SEP]\")\n",
        "      #sentences.append(\"[CLS] \" + str(speaker) + \" [SEP]\" + str(text) + \" [SEP]\")      \n",
        "      #sentences.append(\"[CLS] \" + str(bf_text) + \" [SEP]\" + str(text) + \" [SEP]\")\n",
        "      #sentences.append(\"[CLS] \" + str(bf_text) + \" [SEP]\" + str(speaker) + \" [SEP]\" + str(text) + \" [SEP]\")\n",
        "      sentences.append(\"[CLS]\" + str(bf_text) + \"[SEP]\" + \"[\" + str(speaker) + \"] \" + str(text) + \"[SEP]\")\n",
        "\n",
        "      bf_text = str(text)\n",
        "    \n",
        "\n",
        "    # 텍스트 평균, MAX길이 구하기\n",
        "    max_length = 0\n",
        "    average_length = 0\n",
        "\n",
        "    for i, text in enumerate(sentences):  \n",
        "      text_length = len(text)\n",
        "      average_length += text_length\n",
        "        \n",
        "      if text_length > max_length:\n",
        "        max_length = text_length\n",
        "      \n",
        "      #print(i, text, text_length)\n",
        "\n",
        "    average_length /= len(sentences)    \n",
        "\n",
        "    print(\"Max Text Length\", max_length)\n",
        "    print(\"Average Text Length\", average_length)\n",
        "\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    # 입력 토큰의 최대 시퀀스 길이\n",
        "    MAX_LEN = 128\n",
        "    # 토큰을 숫자 인덱스로 변환\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # 어텐션 마스크 초기화\n",
        "    attention_masks = []\n",
        "\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    if not final_flag:\n",
        "      labels = [e2i_dict[label] for label in labels]\n",
        "\n",
        "    # 데이터를 파이토치의 텐서로 변환\n",
        "    ebd_inputs = torch.tensor(input_ids)\n",
        "    ebd_labels = torch.tensor(labels)\n",
        "    ebd_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    #print(train_inputs[0], train_labels[0], train_masks[0])\n",
        "\n",
        "    if not final_flag:\n",
        "      ebd_data = TensorDataset(ebd_inputs, ebd_masks, ebd_labels)\n",
        "      ebd_sampler = RandomSampler(ebd_data)\n",
        "      ebd_dataloader = DataLoader(ebd_data, sampler=ebd_sampler, batch_size=batch_size)\n",
        "    else:\n",
        "      ebd_data = TensorDataset(ebd_inputs, ebd_masks, ebd_labels)\n",
        "      ebd_dataloader = DataLoader(ebd_data, batch_size=batch_size)\n",
        "\n",
        "    return ebd_dataloader\n",
        "\n",
        "train_dataloader = Embedding( data['train']['utterance'], data['train']['speaker'], data['train']['emotion'], batch_size)   \n",
        "validation_dataloader = Embedding( data['dev']['utterance'], data['dev']['speaker'], data['dev']['emotion'], batch_size)   \n",
        "test_dataloader = Embedding( data['test']['utterance'], data['test']['speaker'], data['test']['emotion'], batch_size)   \n",
        "final_test_dataloader = Embedding( test_data['utterance'], test_data['speaker'], test_data['id'], 1, True)   "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Text Length 588\n",
            "Average Text Length 176.7609958506224\n",
            "Max Text Length 348\n",
            "Average Text Length 101.78268251273344\n",
            "Max Text Length 338\n",
            "Average Text Length 105.58357452966715\n",
            "Max Text Length 304\n",
            "Average Text Length 104.6746765249538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_ZNt0YAq88H"
      },
      "source": [
        "#model = BertForSequenceClassification.from_pretrained(pretrained_weights, num_labels = 8)\n",
        "#model = ElectraForSequenceClassification.from_pretrained(pretrained_weights, num_labels = 8)\n",
        "#model = BertForMultiLabelClassification.from_pretrained(pretrained_weights, config=config)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPsysHZvePul"
      },
      "source": [
        "# Bert모델에 LinearClassfier를 붙여 분류모델 생성\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden_size = 768 # large 1024    \n",
        "    self.num_labels = len(e2i_dict)\n",
        "    self.bert_tokenizer = BertTokenizer.from_pretrained(pretrained_weights)    \n",
        "    self.bert_model = BertModel.from_pretrained(pretrained_weights)\n",
        "    self.classifier = torch.nn.Linear(self.hidden_size, self.num_labels)\n",
        "\n",
        "  def forward(self, b_input_ids, attention_mask, labels=None, weights=None):   \n",
        "\n",
        "    hidden_tensor = self.bert_model(input_ids=b_input_ids, attention_mask=attention_mask)[0] # (bat, len, hid)\n",
        "    hidden_tensor = hidden_tensor[:, 0, :] # (bat, hid)\n",
        "\n",
        "    x = hidden_tensor\n",
        "    logits = self.classifier(x)\n",
        "\n",
        "    if labels is not None:\n",
        "      loss_fct = torch.nn.CrossEntropyLoss().to(device) # LogSoftmax & NLLLoss weight=weights    \n",
        "      loss = loss_fct(logits, labels)\n",
        "    else:\n",
        "      loss = None\n",
        "    \n",
        "    return loss, logits\n",
        "\n",
        "model = Model()    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVU9HqHc3Tsz"
      },
      "source": [
        "'''\n",
        "# Electra 등 다른 모델 생성\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden_size = 512#768 #large 1024    \n",
        "    self.num_labels = len(e2i_dict)\n",
        "    #self.bert_tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
        "    self.bert_tokenizer = ElectraTokenizer.from_pretrained(pretrained_weights)\n",
        "    #self.bert_model = BertModel.from_pretrained(pretrained_weights)\n",
        "    self.bert_model = ElectraModel.from_pretrained(pretrained_weights)\n",
        "    self.linear = torch.nn.Linear(self.hidden_size, 256) \n",
        "    self.dropout = torch.nn.Dropout(0.1)\n",
        "    self.classifier = torch.nn.Linear(256, self.num_labels)\n",
        "\n",
        "  def forward(self, b_input_ids, attention_mask, labels=None, weights=None):   \n",
        "\n",
        "    hidden_tensor = self.bert_model(input_ids=b_input_ids, attention_mask=attention_mask)[0] # (bat, len, hid)\n",
        "    hidden_tensor = hidden_tensor[:, 0, :] # (bat, hid)\n",
        "\n",
        "    x = hidden_tensor\n",
        "    #x = self.linear(hidden_tensor)    \n",
        "    #x = self.dropout(x)\n",
        "    #x = F.gelu(x)  # although BERT uses tanh here, it seems Electra authors used gelu here\n",
        "    #x = self.dropout(x)\n",
        "    logits = self.classifier(x)\n",
        "\n",
        "    #logits = self.linear(hidden_tensor)\n",
        "\n",
        "    if labels is not None:\n",
        "      loss_fct = torch.nn.CrossEntropyLoss().to(device) # LogSoftmax & NLLLoss weight=weights      \n",
        "      #loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "      loss = loss_fct(logits, labels)\n",
        "    else:\n",
        "      loss = None\n",
        "    \n",
        "    return loss, logits\n",
        "\n",
        "model = Model()    \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rY4IzREYyRO",
        "outputId": "145882de-56bd-4e9e-f39a-495751f0a2a6"
      },
      "source": [
        "model.to(device) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (bert_model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "273RBAszJMGd"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# 정확도 계산 함수1\n",
        "def evaluate(true_list, pred_list):\n",
        "  precision = precision_score(true_list, pred_list, average=None)\n",
        "  recall = recall_score(true_list, pred_list, average=None)\n",
        "  micro_f1 = f1_score(true_list, pred_list, average='micro')\n",
        "  print('precision:\\t', ['%.4f' % v for v in precision])\n",
        "  print('recall:\\t\\t', ['%.4f' % v for v in recall])\n",
        "  print('micro_f1: %.6f' % micro_f1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZpOM0cBSa5x"
      },
      "source": [
        "# 정확도 계산 함수2\n",
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    #evaluate(labels_flat, pred_flat)\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUY7pdLAyEDq"
      },
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr =1e-6, # 학습률  1e-5 (1×10-5, 0.00001), 2e-5\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 1\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHbmpiutPfYh"
      },
      "source": [
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QjokwUNLEhC",
        "outputId": "b9dbd2ef-f6f1-4fc1-fb82-37bee9387270"
      },
      "source": [
        "# 클래스 불균형 문제가 있습니다. (가중 교차 엔트로피 사용 등)\n",
        "# {'anger': 0, 'joy': 1, 'sadness': 2, 'disgust': 3,  'neutral': 4,  'surprise': 5 'fear': 6, 'non-neutral': 7 }\n",
        "#nSamples = [513, 185,\t1283, 240, 2017, 351, 4752, 1220]\n",
        "nSamples = [3222, 8044, 6148, 240, 4752, 1939, 2558, 2017]\n",
        "#normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
        "normedWeights = [sum(nSamples)/x for x in nSamples]\n",
        "#print(normedWeights)\n",
        "normedWeights = torch.FloatTensor(normedWeights).to()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 1000 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device\n",
        "                           ) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        #if step == 0:\n",
        "          #print(b_input_ids, '\\n\\n', b_input_mask, '\\n\\n', b_labels)\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels#)\n",
        "                       ,  weights=normedWeights)\n",
        "\n",
        "         # 로스 구함\n",
        "        loss = outputs[0]               \n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()        \n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "     # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids,  \n",
        "                            attention_mask=b_input_mask) \n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[1] #custom class일경우 1\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        #evaluate(logits, label_ids)\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch 1,000  of  14,460.    Elapsed: 0:01:25.\n",
            "  Batch 2,000  of  14,460.    Elapsed: 0:02:52.\n",
            "  Batch 3,000  of  14,460.    Elapsed: 0:04:19.\n",
            "  Batch 4,000  of  14,460.    Elapsed: 0:05:47.\n",
            "  Batch 5,000  of  14,460.    Elapsed: 0:07:15.\n",
            "  Batch 6,000  of  14,460.    Elapsed: 0:08:42.\n",
            "  Batch 7,000  of  14,460.    Elapsed: 0:10:10.\n",
            "  Batch 8,000  of  14,460.    Elapsed: 0:11:37.\n",
            "  Batch 9,000  of  14,460.    Elapsed: 0:13:05.\n",
            "  Batch 10,000  of  14,460.    Elapsed: 0:14:32.\n",
            "  Batch 11,000  of  14,460.    Elapsed: 0:15:59.\n",
            "  Batch 12,000  of  14,460.    Elapsed: 0:17:27.\n",
            "  Batch 13,000  of  14,460.    Elapsed: 0:18:55.\n",
            "  Batch 14,000  of  14,460.    Elapsed: 0:20:22.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:21:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.58\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyZBfRv6Jize",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc6b1df-1456-404e-cbde-54b64ec3a31a"
      },
      "source": [
        "# 테스트셋 평가\r\n",
        "# 평가모드로 변경\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# 변수 초기화\r\n",
        "pred_list, true_list = [], []\r\n",
        "\r\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "for batch in test_dataloader:\r\n",
        "    # 배치를 GPU에 넣음\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    \r\n",
        "    # 배치에서 데이터 추출\r\n",
        "    b_input_ids, b_input_mask, b_labels = batch\r\n",
        "    \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids,  \r\n",
        "                        attention_mask=b_input_mask) \r\n",
        "    \r\n",
        "    # 로스 구함\r\n",
        "    logits = outputs[1] #custom class일경우 1\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    label_ids = b_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "    pred_flat = np.argmax(logits, axis=1).flatten()\r\n",
        "    labels_flat = label_ids.flatten()\r\n",
        "\r\n",
        "    pred_list += pred_flat.tolist()\r\n",
        "    true_list += labels_flat.tolist()\r\n",
        "\r\n",
        "evaluate(pred_list, true_list) # print results"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision:\t ['0.0000', '0.6809', '0.2941', '0.0000', '0.3013', '0.6503', '0.8671', '0.1801']\n",
            "recall:\t\t ['0.0000', '0.5447', '0.4630', '0.0000', '0.3918', '0.5299', '0.7318', '0.8056']\n",
            "micro_f1: 0.624457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt5mM3GGcE11"
      },
      "source": [
        "# 캐글 테스트셋 평가 및 결과저장\r\n",
        "#시작 시간 설정\r\n",
        "t0 = time.time()\r\n",
        "batch = 1\r\n",
        "\r\n",
        "# 평가모드로 변경\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# 변수 초기화\r\n",
        "eval_loss, eval_accuracy = 0, 0\r\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "final_result = []\r\n",
        "\r\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "for step, batch in enumerate(final_test_dataloader):\r\n",
        "    # 경과 정보 표시\r\n",
        "    if step % 1000 == 0 and not step == 0:\r\n",
        "        elapsed = format_time(time.time() - t0)\r\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(final_test_dataloader), elapsed))\r\n",
        "\r\n",
        "    # 배치를 GPU에 넣음\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    \r\n",
        "    # 배치에서 데이터 추출\r\n",
        "    b_input_ids, b_input_mask, b_id = batch\r\n",
        "    \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids,  \r\n",
        "                            attention_mask=b_input_mask) \r\n",
        "       \r\n",
        "    # 로스 구함\r\n",
        "    logits = outputs[1] #custom class일경우 1\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "\r\n",
        "    pred_flat = np.argmax(logits, axis=1).flatten()\r\n",
        "    b_id = b_id.cpu().numpy()\r\n",
        "    #print(b_id, pred_flat)\r\n",
        "\r\n",
        "    result = np.concatenate((b_id, i2e_dict[int(pred_flat)]), axis=None)\r\n",
        "        \r\n",
        "    final_result.append(result)    \r\n",
        "\r\n",
        "#긍정(1) 혹은 부정(0)으로 분류\r\n",
        "rdf = pd.DataFrame(final_result, columns =['Id', 'Expected'])\r\n",
        "rdf.to_csv(DATA_PATH + 'sample_eng.csv', index=False)\r\n",
        "\r\n",
        "final_result[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37gwRRyBLQJ6"
      },
      "source": [
        "# 모델 저장하기\n",
        "torch.save(model.state_dict(), DATA_PATH +  \"friends_model.pt\")"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}